version: "3.8"

services:

  # Portainer service
  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    privileged: true
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    environment:
      - VIRTUAL_HOST=*
      - VIRTUAL_PORT=9000
      - ENABLE_EDGE_AGENT=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer-data:/data
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    labels:
      - com.centurylinklabs.watchtower.enable=false
    ports:
      - "9000:9000"

 
  frontend:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: vulnvision/frontend:latest
    container_name: frontend
    restart: always
    command: ["npm", "run", "start"]
    depends_on:
      - django_httpx_postgres_db
      - django_httpx_redis
    labels:
      - com.centurylinklabs.watchtower.enable=true
    volumes:
      - ./env_files/config.json:/app/public/config.json # Mount the custom config file
    ports:
      - "3000:3000"


  # Start Base server stak
  # Redis
  vulnvision_redis:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: redis:7.2-rc1-alpine
    restart: always
    container_name: vulnvision_redis
    labels:
      - com.centurylinklabs.watchtower.enable=false

  # Postgres database
  vulnvision_postgres_db:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: postgres:15.3
    env_file:
      - env_files/vulnvision_postgres.env
    container_name: vulnvision_postgres_db
    command: postgres -c max_connections=1000
    restart: always
    volumes:
      - vulnvision_op_postgres_db:/var/lib/postgresql/data
    labels:
      - com.centurylinklabs.watchtower.enable=false
    # volumes:
    #   - .postgresql.conf:/var/lib/postgresql/data/postgresql.conf


  # vulnvision service
  vulnvision:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: vulnvision/base:latest
    container_name: base_server
    restart: always
    command: bash -c "sleep 10 && python manage.pyc migrate && python manage.pyc collectstatic --noinput  && python manage.pyc runserver 0.0.0.0:8000"
    env_file:
      - env_files/vulnvision.env
    ports:
      - 8000:8000
    depends_on:
      - vulnvision_postgres_db
      - vulnvision_redis
    labels:
      - com.centurylinklabs.watchtower.enable=true
    volumes:
      - ./static/:/vulnvision/static
      - ./media/:/vulnvision/media
      - /tmp/gvm/gvmd:/tmp/gvm/gvmd

  # vulnvision normal worker
  vulnvision_beat:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: vulnvision/base:latest
    container_name: base_server_beat
    restart: always
    command: bash -c "celery -A vulnvision.celery beat"
    env_file:
      - env_files/vulnvision.env
    depends_on:
      - vulnvision_postgres_db
      - vulnvision_redis
    labels:
      - com.centurylinklabs.watchtower.enable=true
    volumes:
      - /tmp/gvm/gvmd:/tmp/gvm/gvmd


  # vulnvision normal worker
  vulnvision_normal_worker:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: vulnvision/base:latest
    container_name: base_server_normal_worker
    restart: always
    command: bash -c "celery -A vulnvision.celery worker -E"
    env_file:
      - env_files/vulnvision.env
    depends_on:
      - vulnvision_postgres_db
      - vulnvision_redis
    labels:
      - com.centurylinklabs.watchtower.enable=true
    volumes:
      - /tmp/gvm/gvmd:/tmp/gvm/gvmd

  # vulnvision Celery workers
  vulnvision_subdomains_worker:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: vulnvision/base:latest
    container_name: base_server_subdomains_worker
    restart: always
    command: bash -c "celery -A vulnvision.celery worker -Q subdomains,read_write -E"
    env_file:
      - env_files/vulnvision.env
    depends_on:
      - vulnvision_postgres_db
      - vulnvision_redis
    labels:
      - com.centurylinklabs.watchtower.enable=true
    volumes:
      - /tmp/gvm/gvmd:/tmp/gvm/gvmd

  vulnvision_fullscan_worker:
    sysctls:
      - net.ipv4.tcp_window_scaling=1
      - net.ipv4.tcp_congestion_control=cubic
    image: vulnvision/base:latest
    container_name: base_server_acunetix_worker
    restart: always
    command: bash -c "celery -A vulnvision.celery worker -Q fullscan,assessment -E"
    env_file:
      - env_files/vulnvision.env
    depends_on:
      - vulnvision_postgres_db
      - vulnvision_redis
    labels:
      - com.centurylinklabs.watchtower.enable=true
    volumes:
      - /tmp/gvm/gvmd:/tmp/gvm/gvmd


  scanners:
    image: vulnvision/scanners:main  # The tag you used when building your Docker image
    ports:
      - "8080:8080"  # Map port 8080 on the host to port 8080 in the container
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Mount the Docker socket if your app needs to manage Docker containers
    restart: always  # Optional: Ensures the container restarts automatically if it crashes
    environment:
      - GIN_MODE=release  # Set environment variables if your app requires them

    command: bash -c "./microservices-app"

  # Start GVM Stack
  vulnerability-tests:
    image: greenbone/vulnerability-tests
    environment:
      STORAGE_PATH: /var/lib/openvas/22.04/vt-data/nasl
    volumes:
      - vt_data_vol:/mnt

  notus-data:
    image: greenbone/notus-data
    volumes:
      - notus_data_vol:/mnt

  scap-data:
    image: greenbone/scap-data
    volumes:
      - scap_data_vol:/mnt

  cert-bund-data:
    image: greenbone/cert-bund-data
    volumes:
      - cert_data_vol:/mnt

  dfn-cert-data:
    image: greenbone/dfn-cert-data
    volumes:
      - cert_data_vol:/mnt
    depends_on:
      - cert-bund-data

  data-objects:
    image: greenbone/data-objects
    volumes:
      - data_objects_vol:/mnt

  report-formats:
    image: greenbone/report-formats
    volumes:
      - data_objects_vol:/mnt
    depends_on:
      - data-objects

  gpg-data:
    image: greenbone/gpg-data
    volumes:
      - gpg_data_vol:/mnt

  redis-server:
    image: greenbone/redis-server
    restart: on-failure
    volumes:
      - redis_socket_vol:/run/redis/

  pg-gvm:
    image: greenbone/pg-gvm:stable
    restart: on-failure
    volumes:
      - psql_data_vol:/var/lib/postgresql
      - psql_socket_vol:/var/run/postgresql

  gvmd:
    image: greenbone/gvmd:stable
    restart: on-failure
    volumes:
      - gvmd_data_vol:/var/lib/gvm
      - scap_data_vol:/var/lib/gvm/scap-data/
      - cert_data_vol:/var/lib/gvm/cert-data
      - data_objects_vol:/var/lib/gvm/data-objects/gvmd
      - vt_data_vol:/var/lib/openvas/plugins
      - psql_data_vol:/var/lib/postgresql
      - /tmp/gvm/gvmd:/run/gvmd
      - ospd_openvas_socket_vol:/run/ospd
      - psql_socket_vol:/var/run/postgresql
    depends_on:
      pg-gvm:
        condition: service_started
      scap-data:
        condition: service_completed_successfully
      cert-bund-data:
        condition: service_completed_successfully
      dfn-cert-data:
        condition: service_completed_successfully
      data-objects:
        condition: service_completed_successfully
      report-formats:
        condition: service_completed_successfully

  gsa:
    image: greenbone/gsa:stable
    restart: on-failure
    ports:
      - 127.0.0.1:9392:80
    volumes:
      - /tmp/gvm/gvmd:/run/gvmd
    depends_on:
      - gvmd

  ospd-openvas:
    image: greenbone/ospd-openvas:stable
    restart: on-failure
    init: true
    hostname: ospd-openvas.local
    cap_add:
      - NET_ADMIN # for capturing packages in promiscuous mode
      - NET_RAW # for raw sockets e.g. used for the boreas alive detection
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    command:
      [
        "ospd-openvas",
        "-f",
        "--config",
        "/etc/gvm/ospd-openvas.conf",
        "--mqtt-broker-address",
        "mqtt-broker",
        "--notus-feed-dir",
        "/var/lib/notus/advisories",
        "-m",
        "666"
      ]
    volumes:
      - gpg_data_vol:/etc/openvas/gnupg
      - vt_data_vol:/var/lib/openvas/plugins
      - notus_data_vol:/var/lib/notus
      - ospd_openvas_socket_vol:/run/ospd
      - redis_socket_vol:/run/redis/
    depends_on:
      redis-server:
        condition: service_started
      gpg-data:
        condition: service_completed_successfully
      vulnerability-tests:
        condition: service_completed_successfully

  mqtt-broker:
    restart: on-failure
    image: greenbone/mqtt-broker
    networks:
      default:
        aliases:
          - mqtt-broker
          - broker

  notus-scanner:
    restart: on-failure
    image: greenbone/notus-scanner:stable
    volumes:
      - notus_data_vol:/var/lib/notus
      - gpg_data_vol:/etc/openvas/gnupg
    environment:
      NOTUS_SCANNER_MQTT_BROKER_ADDRESS: mqtt-broker
      NOTUS_SCANNER_PRODUCTS_DIRECTORY: /var/lib/notus/products
    depends_on:
      - mqtt-broker
      - gpg-data
      - vulnerability-tests

  gvm-tools:
    image: greenbone/gvm-tools
    volumes:
      - gvmd_socket_vol:/run/gvmd
      - ospd_openvas_socket_vol:/run/ospd
    depends_on:
      - gvmd
      - ospd-openvas



volumes:
  portainer-data:
  prometheus_data:
  dash_build:
  teams_build:
  vulnvision_op_postgres_db:
  django_httpx_postgres_db:
  django_nmap_postgres_db:
  django_nuclei_postgres_db:
  gpg_data_vol:
  scap_data_vol:
  cert_data_vol:
  data_objects_vol:
  gvmd_data_vol:
  psql_data_vol:
  vt_data_vol:
  notus_data_vol:
  psql_socket_vol:
  gvmd_socket_vol:
  ospd_openvas_socket_vol:
  redis_socket_vol:


